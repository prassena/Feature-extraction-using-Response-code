{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>4. Machine Learning Model </h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import libraries\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import lightgbm as lgb\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from tqdm import tqdm_notebook as tqdm\n",
    "from sklearn import metrics\n",
    "import gc\n",
    "import warnings\n",
    "import os\n",
    "pd.set_option('display.max_columns', 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.1 Reading data from file and storing to variable </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loaing Data\n",
    "train_df = pd.read_csv('train.csv') \n",
    "test_df = pd.read_csv('test.csv')\n",
    "\n",
    "#Features for prediction(Indipendent variable)\n",
    "features = [c for c in train_df.columns if c not in ['ID_code', 'target']] \n",
    "target = train_df['target']  #Labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.2 Feature Extraction using response coading for train data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Responce coding \n",
    "def t_encoding(tr,va,by):\n",
    "    \"\"\"Given two data frame (train and test) and feature (column name) ,the responce code fot that feature is calculated from\\\n",
    "    train dataframe and map it to test dataframe\"\"\"\n",
    "    #what is responce coding?\n",
    "    #for given X how many number of times Y occured /total number of times X occured \n",
    "    #ie y=1 intersection of X/ total number of times X occured \n",
    "    \n",
    "    \n",
    "    #calculating responce code\n",
    "    df = tr.groupby(by).agg({'target':['sum','count']})\n",
    "    cols = ['sum_y','count_y']\n",
    "    df.columns = cols\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by)\n",
    "    \n",
    "\n",
    "    df['r'] = df['sum_y'] / df['count_y']  \n",
    "    df.drop(['sum_y','count_y'],axis=1,inplace=True)\n",
    "    \n",
    "    #return mapped value \n",
    "    return va.merge(df,on=by,how='left')['r'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c8d93ccca6f462e98314463a6320f46",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "var_cols = features\n",
    "\n",
    "#calling responce code function with each feature value and appending the return value to test dataset\n",
    "for col in tqdm(var_cols):\n",
    "    te_r = t_encoding(train_df,test_df,col) \n",
    "    test_df.loc[:,col+'_r'] = te_r\n",
    "test_df.to_csv(\"test_df_after_responce_coding.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 4.3 Feature Extraction using response coading for test data</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cccfd5b12342518d39e61bacf498dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 1\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "186e7f9206134676a78bb9b00be6ad9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 2\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "57aad9fb4a01430c8a79959c8a1bd078",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 3\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e568c2e68b647138ff9a40b90662585",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 4\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03e89aefcf2c44e3a15339151cb8618e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 5\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "31dec0573c56468a92b959f313a02cac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 6\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9357b839505e4d46b57e8a40ab1781ee",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Fold 7\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdf8eb44469c450aa96ba2b81a68e64e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=200), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "data prepared: (200000, 400)\n"
     ]
    }
   ],
   "source": [
    "#https://www.kaggle.com/c/santander-customer-transaction-prediction/discussion/88950\n",
    "#spliting train data using StratifiedKFold and getting responce code for train data\n",
    "folds = StratifiedKFold(n_splits=8, shuffle=False, random_state=99999)\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "    tr = train_df.loc[trn_idx,var_cols+['target']]\n",
    "    va = train_df.loc[val_idx,var_cols+['target']]\n",
    "\n",
    "    for col in tqdm(var_cols):\n",
    "        encoded = t_encoding(tr,va,col)\n",
    "        train_df.loc[val_idx,col+'_r'] = encoded\n",
    "        \n",
    "features = [col for col in train_df.columns if ('var' in col)]\n",
    "\n",
    "train_df = train_df[features].reset_index(drop=True)\n",
    "print('data prepared: {}'.format(train_df.shape))\n",
    "train_df.to_csv(\"train_df_after_responce_coding.csv\",index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5. LightGBM optimization</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving all feature name to a variable as list\n",
    "predictors = train_df.columns.values.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#StratifiedKFold with 2 fold .using for optimization\n",
    "bayesian_tr_index, bayesian_val_index  = list(StratifiedKFold(n_splits=2, shuffle=True, random_state=1).split(train_df, target))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5.1 Setting paramaters to optimize </h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#https://www.kaggle.com/fayzur/lgb-bayesian-parameters-finding-rank-average\n",
    "def LGB_bayesian(\n",
    "    num_leaves,  # int\n",
    "    min_data_in_leaf,  # int\n",
    "    max_bin,\n",
    "    learning_rate,\n",
    "    lambda_l1,\n",
    "    lambda_l2,\n",
    "    min_gain_to_split,\n",
    "    max_depth):\n",
    "    \n",
    "    # LightGBM expects next three parameters need to be integer. So we make them integer\n",
    "    num_leaves = int(num_leaves)\n",
    "    min_data_in_leaf = int(min_data_in_leaf)\n",
    "    max_depth = int(max_depth)\n",
    "    max_bin = int(max_bin)\n",
    "\n",
    "    \n",
    "    param = {\n",
    "        'num_leaves': num_leaves,\n",
    "        'max_bin': max_bin,\n",
    "        'min_data_in_leaf': min_data_in_leaf,\n",
    "        'learning_rate': learning_rate,\n",
    "        'bagging_fraction': 1.0,\n",
    "        'bagging_freq': 5,\n",
    "        'feature_fraction': 1,\n",
    "        'lambda_l1': lambda_l1,\n",
    "        'lambda_l2': lambda_l2,\n",
    "        'min_gain_to_split': min_gain_to_split,\n",
    "        'max_depth': max_depth,\n",
    "        'save_binary': True, \n",
    "        'seed': 1337,\n",
    "        'feature_fraction_seed': 1337,\n",
    "        'bagging_seed': 1337,\n",
    "        'drop_seed': 1337,\n",
    "        'data_random_seed': 1337,\n",
    "        'objective': 'binary',\n",
    "        'boosting_type': 'gbdt',\n",
    "        'verbose': 1,\n",
    "        'metric': 'auc',\n",
    "        'is_unbalance': True,\n",
    "        'boost_from_average': False,}\n",
    "    \n",
    "    # converting train data to lightgbm.basic.Dataset so that it can load faster\n",
    "    xg_train = lgb.Dataset(train_df.iloc[bayesian_tr_index][predictors].values,\n",
    "                           label=target.iloc[bayesian_tr_index].values,\n",
    "                           feature_name=predictors,\n",
    "                           free_raw_data = False\n",
    "                           )\n",
    "    \n",
    "    # converting validation data to lightgbm.basic.Dataset so that it can load faster\n",
    "    xg_valid = lgb.Dataset(train_df.iloc[bayesian_val_index][predictors].values,\n",
    "                           label=target.iloc[bayesian_val_index].values,\n",
    "                           feature_name=predictors,\n",
    "                           free_raw_data = False\n",
    "                           )   \n",
    "    num_round = 5000 #iteration to happen\n",
    "    #training lgb for getting paramaters\n",
    "    clf = lgb.train(param, xg_train, num_round, valid_sets = [xg_valid], verbose_eval=250, early_stopping_rounds = 50)\n",
    "    \n",
    "    predictions = clf.predict(train_df.iloc[bayesian_val_index][predictors].values, num_iteration=clf.best_iteration)   \n",
    "    \n",
    "    #AUC is used metric we are trying to increase\n",
    "    score = metrics.roc_auc_score(target.iloc[bayesian_val_index].values, predictions)\n",
    "    \n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5.2 Setting Range values for each paramaters to optimize</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bounded region of parameter space,values between this range is sent to paramater for optimization\n",
    "bounds_LGB = {\n",
    "    'num_leaves': (5, 20), \n",
    "    'min_data_in_leaf': (5, 20),\n",
    "    'max_bin':(30,60),\n",
    "    'learning_rate': (0.01, 0.3),\n",
    "    'lambda_l1': (0, 3.0), \n",
    "    'lambda_l2': (0, 3.0), \n",
    "    'min_gain_to_split': (0, 1.0),\n",
    "    'max_depth':(3,15),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 5.3 Passing the boundry values to the model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['lambda_l1', 'lambda_l2', 'learning_rate', 'max_bin', 'max_depth', 'min_data_in_leaf', 'min_gain_to_split', 'num_leaves']\n"
     ]
    }
   ],
   "source": [
    "#put all of Bounded parameter in BayesianOptimization object\n",
    "from bayes_opt import BayesianOptimization\n",
    "LGB_BO = BayesianOptimization(LGB_bayesian, bounds_LGB, random_state=13)\n",
    "\n",
    "#print the paramaters we set for optimization\n",
    "print(LGB_BO.space.keys)\n",
    "\n",
    "init_points = 10 #How many steps of random exploration you want to perform\n",
    "n_iter = 8 # How many steps of bayesian optimization you want to perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------------------------------------------------------------------------\n",
      "|   iter    |  target   | lambda_l1 | lambda_l2 | learni... |  max_bin  | max_depth | min_da... | min_ga... | num_le... |\n",
      "-------------------------------------------------------------------------------------------------------------------------\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.882837\n",
      "Early stopping, best iteration is:\n",
      "[211]\tvalid_0's auc: 0.883642\n",
      "|  1        |  0.8836   |  2.333    |  0.7126   |  0.249    |  58.97    |  14.67    |  11.8     |  0.609    |  16.63    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.804866\n",
      "[500]\tvalid_0's auc: 0.840284\n",
      "[750]\tvalid_0's auc: 0.858368\n",
      "[1000]\tvalid_0's auc: 0.86895\n",
      "[1250]\tvalid_0's auc: 0.875757\n",
      "[1500]\tvalid_0's auc: 0.880979\n",
      "[1750]\tvalid_0's auc: 0.884571\n",
      "[2000]\tvalid_0's auc: 0.887243\n",
      "[2250]\tvalid_0's auc: 0.889364\n",
      "[2500]\tvalid_0's auc: 0.891068\n",
      "[2750]\tvalid_0's auc: 0.892416\n",
      "[3000]\tvalid_0's auc: 0.89351\n",
      "[3250]\tvalid_0's auc: 0.894351\n",
      "[3500]\tvalid_0's auc: 0.895055\n",
      "[3750]\tvalid_0's auc: 0.895586\n",
      "[4000]\tvalid_0's auc: 0.896095\n",
      "[4250]\tvalid_0's auc: 0.896413\n",
      "[4500]\tvalid_0's auc: 0.896743\n",
      "[4750]\tvalid_0's auc: 0.897007\n",
      "[5000]\tvalid_0's auc: 0.897131\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4998]\tvalid_0's auc: 0.897137\n",
      "|  2        |  0.8971   |  1.925    |  2.166    |  0.02016  |  38.95    |  3.702    |  17.86    |  0.3729   |  15.2     |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.820464\n",
      "[500]\tvalid_0's auc: 0.852356\n",
      "[750]\tvalid_0's auc: 0.86723\n",
      "[1000]\tvalid_0's auc: 0.875749\n",
      "[1250]\tvalid_0's auc: 0.881536\n",
      "[1500]\tvalid_0's auc: 0.885649\n",
      "[1750]\tvalid_0's auc: 0.888488\n",
      "[2000]\tvalid_0's auc: 0.890784\n",
      "[2250]\tvalid_0's auc: 0.892454\n",
      "[2500]\tvalid_0's auc: 0.893705\n",
      "[2750]\tvalid_0's auc: 0.894693\n",
      "[3000]\tvalid_0's auc: 0.895355\n",
      "[3250]\tvalid_0's auc: 0.895746\n",
      "[3500]\tvalid_0's auc: 0.895997\n",
      "Early stopping, best iteration is:\n",
      "[3698]\tvalid_0's auc: 0.896189\n",
      "|  3        |  0.8962   |  0.7688   |  1.043    |  0.01273  |  40.75    |  14.39    |  8.268    |  0.3194   |  18.77    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.885093\n",
      "[500]\tvalid_0's auc: 0.893598\n",
      "Early stopping, best iteration is:\n",
      "[545]\tvalid_0's auc: 0.893886\n",
      "|  4        |  0.8939   |  0.09571  |  0.1953   |  0.1927   |  56.21    |  3.105    |  16.2     |  0.8128   |  6.136    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.881294\n",
      "[500]\tvalid_0's auc: 0.892218\n",
      "[750]\tvalid_0's auc: 0.894338\n",
      "Early stopping, best iteration is:\n",
      "[757]\tvalid_0's auc: 0.894376\n",
      "|  5        |  0.8944   |  1.969    |  1.528    |  0.1492   |  58.67    |  3.0      |  8.705    |  0.7122   |  9.869    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[176]\tvalid_0's auc: 0.881466\n",
      "|  6        |  0.8815   |  0.831    |  2.086    |  0.2764   |  37.33    |  8.497    |  8.795    |  0.3793   |  14.07    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.886911\n",
      "Early stopping, best iteration is:\n",
      "[445]\tvalid_0's auc: 0.891159\n",
      "|  7        |  0.8912   |  2.317    |  0.2038   |  0.209    |  46.45    |  4.656    |  6.481    |  0.2456   |  7.277    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.878082\n",
      "[500]\tvalid_0's auc: 0.891741\n",
      "[750]\tvalid_0's auc: 0.894408\n",
      "Early stopping, best iteration is:\n",
      "[848]\tvalid_0's auc: 0.894833\n",
      "|  8        |  0.8948   |  2.778    |  2.04     |  0.07892  |  47.07    |  9.68     |  6.091    |  0.8397   |  11.08    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.882676\n",
      "[500]\tvalid_0's auc: 0.89284\n",
      "[750]\tvalid_0's auc: 0.893529\n",
      "Early stopping, best iteration is:\n",
      "[704]\tvalid_0's auc: 0.893591\n",
      "|  9        |  0.8936   |  0.4346   |  0.5728   |  0.1523   |  51.36    |  14.82    |  18.12    |  0.499    |  6.602    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.872755\n",
      "[500]\tvalid_0's auc: 0.888433\n",
      "[750]\tvalid_0's auc: 0.8933\n",
      "[1000]\tvalid_0's auc: 0.894561\n",
      "Early stopping, best iteration is:\n",
      "[1178]\tvalid_0's auc: 0.894911\n",
      "|  10       |  0.8949   |  2.74     |  1.095    |  0.07571  |  56.17    |  4.636    |  8.546    |  0.5954   |  13.46    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "Early stopping, best iteration is:\n",
      "[144]\tvalid_0's auc: 0.878272\n",
      "|  11       |  0.8783   |  3.0      |  3.0      |  0.3      |  30.0     |  15.0     |  20.0     |  0.7105   |  20.0     |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.857896\n",
      "[500]\tvalid_0's auc: 0.880348\n",
      "[750]\tvalid_0's auc: 0.888917\n",
      "[1000]\tvalid_0's auc: 0.893318\n",
      "[1250]\tvalid_0's auc: 0.895358\n",
      "[1500]\tvalid_0's auc: 0.896461\n",
      "[1750]\tvalid_0's auc: 0.896909\n",
      "Early stopping, best iteration is:\n",
      "[1847]\tvalid_0's auc: 0.897122\n",
      "|  12       |  0.8971   |  0.3315   |  2.531    |  0.06099  |  53.39    |  3.158    |  19.87    |  0.4794   |  19.25    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.888005\n",
      "[500]\tvalid_0's auc: 0.893168\n",
      "Early stopping, best iteration is:\n",
      "[513]\tvalid_0's auc: 0.893305\n",
      "|  13       |  0.8933   |  2.977    |  2.954    |  0.272    |  50.85    |  3.162    |  19.76    |  0.2104   |  5.845    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.842699\n",
      "[500]\tvalid_0's auc: 0.868235\n",
      "[750]\tvalid_0's auc: 0.878717\n",
      "[1000]\tvalid_0's auc: 0.885147\n",
      "[1250]\tvalid_0's auc: 0.88958\n",
      "[1500]\tvalid_0's auc: 0.89255\n",
      "[1750]\tvalid_0's auc: 0.894299\n",
      "[2000]\tvalid_0's auc: 0.895492\n",
      "[2250]\tvalid_0's auc: 0.896285\n",
      "[2500]\tvalid_0's auc: 0.896837\n",
      "[2750]\tvalid_0's auc: 0.897252\n",
      "[3000]\tvalid_0's auc: 0.897581\n",
      "Early stopping, best iteration is:\n",
      "[3040]\tvalid_0's auc: 0.897647\n",
      "|  14       |  0.8976   |  0.5506   |  0.07411  |  0.04551  |  59.19    |  12.01    |  5.082    |  0.004802 |  5.083    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.781234\n",
      "[500]\tvalid_0's auc: 0.820339\n",
      "[750]\tvalid_0's auc: 0.840765\n",
      "[1000]\tvalid_0's auc: 0.853311\n",
      "[1250]\tvalid_0's auc: 0.861961\n",
      "[1500]\tvalid_0's auc: 0.868241\n",
      "[1750]\tvalid_0's auc: 0.872843\n",
      "[2000]\tvalid_0's auc: 0.87653\n",
      "[2250]\tvalid_0's auc: 0.879473\n",
      "[2500]\tvalid_0's auc: 0.881854\n",
      "[2750]\tvalid_0's auc: 0.883773\n",
      "[3000]\tvalid_0's auc: 0.885537\n",
      "[3250]\tvalid_0's auc: 0.886915\n",
      "[3500]\tvalid_0's auc: 0.888029\n",
      "[3750]\tvalid_0's auc: 0.8891\n",
      "[4000]\tvalid_0's auc: 0.889965\n",
      "[4250]\tvalid_0's auc: 0.890724\n",
      "[4500]\tvalid_0's auc: 0.891402\n",
      "[4750]\tvalid_0's auc: 0.891951\n",
      "[5000]\tvalid_0's auc: 0.892448\n",
      "Did not meet early stopping. Best iteration is:\n",
      "[4998]\tvalid_0's auc: 0.892453\n",
      "|  15       |  0.8925   |  0.03614  |  1.05     |  0.01     |  49.39    |  4.887    |  5.237    |  0.866    |  19.64    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.835271\n",
      "[500]\tvalid_0's auc: 0.86459\n",
      "[750]\tvalid_0's auc: 0.8774\n",
      "[1000]\tvalid_0's auc: 0.88465\n",
      "[1250]\tvalid_0's auc: 0.889004\n",
      "[1500]\tvalid_0's auc: 0.891903\n",
      "[1750]\tvalid_0's auc: 0.893876\n",
      "[2000]\tvalid_0's auc: 0.895212\n",
      "[2250]\tvalid_0's auc: 0.896171\n",
      "[2500]\tvalid_0's auc: 0.896792\n",
      "Early stopping, best iteration is:\n",
      "[2586]\tvalid_0's auc: 0.896979\n",
      "|  16       |  0.897    |  2.539    |  0.2337   |  0.03608  |  42.0     |  3.898    |  19.93    |  0.5415   |  18.57    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.887301\n",
      "Early stopping, best iteration is:\n",
      "[278]\tvalid_0's auc: 0.887792\n",
      "|  17       |  0.8878   |  0.2794   |  2.577    |  0.1552   |  44.83    |  12.7     |  18.46    |  0.1199   |  19.58    |\n",
      "Training until validation scores don't improve for 50 rounds\n",
      "[250]\tvalid_0's auc: 0.834808\n",
      "[500]\tvalid_0's auc: 0.862536\n",
      "[750]\tvalid_0's auc: 0.87476\n",
      "[1000]\tvalid_0's auc: 0.881643\n",
      "[1250]\tvalid_0's auc: 0.886496\n",
      "[1500]\tvalid_0's auc: 0.889945\n",
      "[1750]\tvalid_0's auc: 0.892146\n",
      "[2000]\tvalid_0's auc: 0.893752\n",
      "[2250]\tvalid_0's auc: 0.894678\n",
      "[2500]\tvalid_0's auc: 0.895145\n",
      "[2750]\tvalid_0's auc: 0.895559\n",
      "[3000]\tvalid_0's auc: 0.895844\n",
      "Early stopping, best iteration is:\n",
      "[3134]\tvalid_0's auc: 0.896001\n",
      "|  18       |  0.896    |  0.04674  |  0.3238   |  0.0332   |  30.93    |  14.64    |  19.71    |  0.3106   |  6.735    |\n",
      "=========================================================================================================================\n"
     ]
    }
   ],
   "source": [
    "print('-' * 130)\n",
    "#this is where the optimization starts. .maximize function starts the optimization process\n",
    "with warnings.catch_warnings():\n",
    "    warnings.filterwarnings('ignore')\n",
    "    LGB_BO.maximize(init_points=init_points, n_iter=n_iter, acq='ucb', xi=0.0, alpha=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: \n",
      "\t{'target': 0.8836415176379367, 'params': {'lambda_l1': 2.3331072317214607, 'lambda_l2': 0.7126236601047369, 'learning_rate': 0.24904077447179687, 'max_bin': 58.97247594128999, 'max_depth': 14.67121336685872, 'min_data_in_leaf': 11.801738711259683, 'min_gain_to_split': 0.6090424627612779, 'num_leaves': 16.6328977190727}}\n",
      "Iteration 1: \n",
      "\t{'target': 0.8971366338006215, 'params': {'lambda_l1': 1.9248400342772074, 'lambda_l2': 2.1660546885508416, 'learning_rate': 0.02016059198941682, 'max_bin': 38.95348412667538, 'max_depth': 3.702149902584897, 'min_data_in_leaf': 17.855914138807982, 'min_gain_to_split': 0.3728540278748075, 'num_leaves': 15.197719273671455}}\n",
      "Iteration 2: \n",
      "\t{'target': 0.8961888416556874, 'params': {'lambda_l1': 0.7688398479798904, 'lambda_l2': 1.0427436454574759, 'learning_rate': 0.01272970332348113, 'max_bin': 40.7500134811491, 'max_depth': 14.389130180138524, 'min_data_in_leaf': 8.268485136975334, 'min_gain_to_split': 0.3193913663803646, 'num_leaves': 18.76658579000881}}\n",
      "Iteration 3: \n",
      "\t{'target': 0.8938855598053246, 'params': {'lambda_l1': 0.09571099931968419, 'lambda_l2': 0.19525361112754347, 'learning_rate': 0.19265040974126865, 'max_bin': 56.21440329838616, 'max_depth': 3.1045887876454183, 'min_data_in_leaf': 16.198658554909063, 'min_gain_to_split': 0.8128411710026234, 'num_leaves': 6.135761692584001}}\n",
      "Iteration 4: \n",
      "\t{'target': 0.8943760281848434, 'params': {'lambda_l1': 1.9693660037908733, 'lambda_l2': 1.5277866002505545, 'learning_rate': 0.1491661835339511, 'max_bin': 58.66722434793199, 'max_depth': 3.000144402833821, 'min_data_in_leaf': 8.704680514878746, 'min_gain_to_split': 0.7122326779115835, 'num_leaves': 9.868730746800697}}\n",
      "Iteration 5: \n",
      "\t{'target': 0.8814661523146204, 'params': {'lambda_l1': 0.8309890691514284, 'lambda_l2': 2.0863363576604237, 'learning_rate': 0.2763800069623251, 'max_bin': 37.33427106593971, 'max_depth': 8.497029807321164, 'min_data_in_leaf': 8.794890242322596, 'min_gain_to_split': 0.37933329148306616, 'num_leaves': 14.068082429475666}}\n",
      "Iteration 6: \n",
      "\t{'target': 0.8911589473323221, 'params': {'lambda_l1': 2.317136279041674, 'lambda_l2': 0.2037524903832435, 'learning_rate': 0.2089646729643209, 'max_bin': 46.447802921874754, 'max_depth': 4.655832633099087, 'min_data_in_leaf': 6.481298288073776, 'min_gain_to_split': 0.24555910532465564, 'num_leaves': 7.276799938767089}}\n",
      "Iteration 7: \n",
      "\t{'target': 0.8948330952896958, 'params': {'lambda_l1': 2.7779834384706534, 'lambda_l2': 2.040315046813926, 'learning_rate': 0.07892108734510815, 'max_bin': 47.06655757669681, 'max_depth': 9.679584617212832, 'min_data_in_leaf': 6.091058163265217, 'min_gain_to_split': 0.8397085104160709, 'num_leaves': 11.07979239047197}}\n",
      "Iteration 8: \n",
      "\t{'target': 0.8935908791836676, 'params': {'lambda_l1': 0.43461296713897535, 'lambda_l2': 0.572760175999781, 'learning_rate': 0.15228563974889664, 'max_bin': 51.3607312274926, 'max_depth': 14.819261492412096, 'min_data_in_leaf': 18.121797526025667, 'min_gain_to_split': 0.499041683900894, 'num_leaves': 6.601699909905633}}\n",
      "Iteration 9: \n",
      "\t{'target': 0.8949112008604669, 'params': {'lambda_l1': 2.7396384209689293, 'lambda_l2': 1.0947478826588548, 'learning_rate': 0.07571048430083423, 'max_bin': 56.172955870362856, 'max_depth': 4.636300221110855, 'min_data_in_leaf': 8.545702402292303, 'min_gain_to_split': 0.5953992453523792, 'num_leaves': 13.458839136180726}}\n",
      "Iteration 10: \n",
      "\t{'target': 0.8782720071810439, 'params': {'lambda_l1': 3.0, 'lambda_l2': 2.999999997012024, 'learning_rate': 0.299999996426226, 'max_bin': 30.000000012786284, 'max_depth': 15.0, 'min_data_in_leaf': 19.999999998787217, 'min_gain_to_split': 0.7105221098115656, 'num_leaves': 20.0}}\n",
      "Iteration 11: \n",
      "\t{'target': 0.8971223404623634, 'params': {'lambda_l1': 0.33152113585206866, 'lambda_l2': 2.531295381768378, 'learning_rate': 0.060989163929997016, 'max_bin': 53.38588021361896, 'max_depth': 3.1584327513444883, 'min_data_in_leaf': 19.867316171089996, 'min_gain_to_split': 0.47943973259511075, 'num_leaves': 19.2539600857298}}\n",
      "Iteration 12: \n",
      "\t{'target': 0.8933050334381197, 'params': {'lambda_l1': 2.9768606198438983, 'lambda_l2': 2.9537636879081304, 'learning_rate': 0.27200123571619367, 'max_bin': 50.852641462097374, 'max_depth': 3.161967630975319, 'min_data_in_leaf': 19.759970124468236, 'min_gain_to_split': 0.2103909577381461, 'num_leaves': 5.845083801792335}}\n",
      "Iteration 13: \n",
      "\t{'target': 0.8976465574933451, 'params': {'lambda_l1': 0.5506494771002205, 'lambda_l2': 0.07411055445001147, 'learning_rate': 0.04551151859925723, 'max_bin': 59.18568109802394, 'max_depth': 12.014120719205591, 'min_data_in_leaf': 5.081842174131943, 'min_gain_to_split': 0.004801800840957271, 'num_leaves': 5.082741376762955}}\n",
      "Iteration 14: \n",
      "\t{'target': 0.8924529480258521, 'params': {'lambda_l1': 0.03614487721084586, 'lambda_l2': 1.0504822513140006, 'learning_rate': 0.010000054921851449, 'max_bin': 49.390290655492805, 'max_depth': 4.886804898143923, 'min_data_in_leaf': 5.236799592560784, 'min_gain_to_split': 0.865978992456049, 'num_leaves': 19.638036324355284}}\n",
      "Iteration 15: \n",
      "\t{'target': 0.8969791482066276, 'params': {'lambda_l1': 2.53878272581532, 'lambda_l2': 0.23373293059128308, 'learning_rate': 0.03607855135032664, 'max_bin': 42.00348892900478, 'max_depth': 3.8984173045510024, 'min_data_in_leaf': 19.928527129474976, 'min_gain_to_split': 0.5415285860672069, 'num_leaves': 18.565960623052987}}\n",
      "Iteration 16: \n",
      "\t{'target': 0.8877923650206527, 'params': {'lambda_l1': 0.27936416412088705, 'lambda_l2': 2.5766737645655016, 'learning_rate': 0.15516159250398143, 'max_bin': 44.83070770446318, 'max_depth': 12.70121149379949, 'min_data_in_leaf': 18.45605943147173, 'min_gain_to_split': 0.1198932715524067, 'num_leaves': 19.580471555840866}}\n",
      "Iteration 17: \n",
      "\t{'target': 0.8960011796384992, 'params': {'lambda_l1': 0.046739727052526825, 'lambda_l2': 0.32379262527617403, 'learning_rate': 0.03320272459514612, 'max_bin': 30.934461457532844, 'max_depth': 14.638201672659651, 'min_data_in_leaf': 19.713927459181996, 'min_gain_to_split': 0.3105500162729372, 'num_leaves': 6.735377778606303}}\n"
     ]
    }
   ],
   "source": [
    "#display all Iterations auc score with the paramates which with which the auc is achived\n",
    "for i, res in enumerate(LGB_BO.res):\n",
    "    print(\"Iteration {}: \\n\\t{}\".format(i, res))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max AUC we got 0.8976465574933451\n",
      "Paramaters which gave maximum AUC {'lambda_l1': 0.5506494771002205, 'lambda_l2': 0.07411055445001147, 'learning_rate': 0.04551151859925723, 'max_bin': 59.18568109802394, 'max_depth': 12.014120719205591, 'min_data_in_leaf': 5.081842174131943, 'min_gain_to_split': 0.004801800840957271, 'num_leaves': 5.082741376762955}\n"
     ]
    }
   ],
   "source": [
    "print(\"Max AUC we got\",LGB_BO.max['target'])\n",
    "print(\"Paramaters which gave maximum AUC\",LGB_BO.max['params'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 6. Training the model with best Paramaters which gave best AUC</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Setting best paramaters\n",
    "param={'max_bin' : int(np.round(LGB_BO.max['params']['max_bin'])),\n",
    "        'lambda_l1': LGB_BO.max['params']['lambda_l1'], \n",
    "        'lambda_l2': LGB_BO.max['params']['lambda_l2'], \n",
    "        'learning_rate': LGB_BO.max['params']['learning_rate'], \n",
    "        'max_depth': int(np.round(LGB_BO.max['params']['max_depth'])), \n",
    "        'min_data_in_leaf': int(np.round(LGB_BO.max['params']['min_data_in_leaf'])), \n",
    "        'min_gain_to_split': LGB_BO.max['params']['min_gain_to_split'], \n",
    "        'num_leaves': int(np.round(LGB_BO.max['params']['num_leaves'])),\n",
    "        'verbosity': 1,\n",
    "        'objective': 'binary',}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_bin': 59,\n",
       " 'lambda_l1': 0.5506494771002205,\n",
       " 'lambda_l2': 0.07411055445001147,\n",
       " 'learning_rate': 0.04551151859925723,\n",
       " 'max_depth': 12,\n",
       " 'min_data_in_leaf': 5,\n",
       " 'min_gain_to_split': 0.004801800840957271,\n",
       " 'num_leaves': 5,\n",
       " 'verbosity': 1,\n",
       " 'objective': 'binary'}"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 0\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.209661\tvalid_1's binary_logloss: 0.224071\n",
      "[2000]\ttraining's binary_logloss: 0.185979\tvalid_1's binary_logloss: 0.207036\n",
      "[3000]\ttraining's binary_logloss: 0.172892\tvalid_1's binary_logloss: 0.201881\n",
      "[4000]\ttraining's binary_logloss: 0.162347\tvalid_1's binary_logloss: 0.199375\n",
      "[5000]\ttraining's binary_logloss: 0.153076\tvalid_1's binary_logloss: 0.198101\n",
      "[6000]\ttraining's binary_logloss: 0.144735\tvalid_1's binary_logloss: 0.197245\n",
      "[7000]\ttraining's binary_logloss: 0.137051\tvalid_1's binary_logloss: 0.196823\n",
      "[8000]\ttraining's binary_logloss: 0.129933\tvalid_1's binary_logloss: 0.196687\n",
      "[9000]\ttraining's binary_logloss: 0.123294\tvalid_1's binary_logloss: 0.196646\n",
      "[10000]\ttraining's binary_logloss: 0.11709\tvalid_1's binary_logloss: 0.196929\n",
      "Early stopping, best iteration is:\n",
      "[8260]\ttraining's binary_logloss: 0.128149\tvalid_1's binary_logloss: 0.196556\n",
      "Fold 1\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.20945\tvalid_1's binary_logloss: 0.224883\n",
      "[2000]\ttraining's binary_logloss: 0.18583\tvalid_1's binary_logloss: 0.207718\n",
      "[3000]\ttraining's binary_logloss: 0.172783\tvalid_1's binary_logloss: 0.202768\n",
      "[4000]\ttraining's binary_logloss: 0.162217\tvalid_1's binary_logloss: 0.200565\n",
      "[5000]\ttraining's binary_logloss: 0.152928\tvalid_1's binary_logloss: 0.199279\n",
      "[6000]\ttraining's binary_logloss: 0.144558\tvalid_1's binary_logloss: 0.198512\n",
      "[7000]\ttraining's binary_logloss: 0.136875\tvalid_1's binary_logloss: 0.198111\n",
      "[8000]\ttraining's binary_logloss: 0.129807\tvalid_1's binary_logloss: 0.197905\n",
      "[9000]\ttraining's binary_logloss: 0.123138\tvalid_1's binary_logloss: 0.197894\n",
      "[10000]\ttraining's binary_logloss: 0.116957\tvalid_1's binary_logloss: 0.198\n",
      "Early stopping, best iteration is:\n",
      "[8268]\ttraining's binary_logloss: 0.127969\tvalid_1's binary_logloss: 0.197856\n",
      "Fold 2\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.209905\tvalid_1's binary_logloss: 0.223303\n",
      "[2000]\ttraining's binary_logloss: 0.186213\tvalid_1's binary_logloss: 0.206278\n",
      "[3000]\ttraining's binary_logloss: 0.173084\tvalid_1's binary_logloss: 0.200914\n",
      "[4000]\ttraining's binary_logloss: 0.162474\tvalid_1's binary_logloss: 0.198846\n",
      "[5000]\ttraining's binary_logloss: 0.153227\tvalid_1's binary_logloss: 0.197648\n",
      "[6000]\ttraining's binary_logloss: 0.144901\tvalid_1's binary_logloss: 0.196992\n",
      "[7000]\ttraining's binary_logloss: 0.137249\tvalid_1's binary_logloss: 0.196492\n",
      "[8000]\ttraining's binary_logloss: 0.130142\tvalid_1's binary_logloss: 0.196392\n",
      "[9000]\ttraining's binary_logloss: 0.123506\tvalid_1's binary_logloss: 0.196361\n",
      "[10000]\ttraining's binary_logloss: 0.117343\tvalid_1's binary_logloss: 0.196437\n",
      "Early stopping, best iteration is:\n",
      "[8531]\ttraining's binary_logloss: 0.126532\tvalid_1's binary_logloss: 0.196284\n",
      "Fold 3\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.210004\tvalid_1's binary_logloss: 0.222824\n",
      "[2000]\ttraining's binary_logloss: 0.1861\tvalid_1's binary_logloss: 0.206101\n",
      "[3000]\ttraining's binary_logloss: 0.172862\tvalid_1's binary_logloss: 0.201064\n",
      "[4000]\ttraining's binary_logloss: 0.162254\tvalid_1's binary_logloss: 0.199039\n",
      "[5000]\ttraining's binary_logloss: 0.153011\tvalid_1's binary_logloss: 0.197883\n",
      "[6000]\ttraining's binary_logloss: 0.144655\tvalid_1's binary_logloss: 0.197214\n",
      "[7000]\ttraining's binary_logloss: 0.136979\tvalid_1's binary_logloss: 0.196713\n",
      "[8000]\ttraining's binary_logloss: 0.129843\tvalid_1's binary_logloss: 0.196467\n",
      "[9000]\ttraining's binary_logloss: 0.123204\tvalid_1's binary_logloss: 0.196493\n",
      "[10000]\ttraining's binary_logloss: 0.117056\tvalid_1's binary_logloss: 0.196467\n",
      "[11000]\ttraining's binary_logloss: 0.111198\tvalid_1's binary_logloss: 0.196656\n",
      "Early stopping, best iteration is:\n",
      "[9326]\ttraining's binary_logloss: 0.121154\tvalid_1's binary_logloss: 0.196409\n",
      "Fold 4\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.210038\tvalid_1's binary_logloss: 0.222466\n",
      "[2000]\ttraining's binary_logloss: 0.186382\tvalid_1's binary_logloss: 0.205304\n",
      "[3000]\ttraining's binary_logloss: 0.173226\tvalid_1's binary_logloss: 0.20012\n",
      "[4000]\ttraining's binary_logloss: 0.162633\tvalid_1's binary_logloss: 0.197693\n",
      "[5000]\ttraining's binary_logloss: 0.153342\tvalid_1's binary_logloss: 0.196429\n",
      "[6000]\ttraining's binary_logloss: 0.144992\tvalid_1's binary_logloss: 0.195539\n",
      "[7000]\ttraining's binary_logloss: 0.137316\tvalid_1's binary_logloss: 0.195129\n",
      "[8000]\ttraining's binary_logloss: 0.13019\tvalid_1's binary_logloss: 0.19496\n",
      "[9000]\ttraining's binary_logloss: 0.123547\tvalid_1's binary_logloss: 0.194895\n",
      "[10000]\ttraining's binary_logloss: 0.117368\tvalid_1's binary_logloss: 0.195027\n",
      "Early stopping, best iteration is:\n",
      "[8558]\ttraining's binary_logloss: 0.126424\tvalid_1's binary_logloss: 0.194876\n",
      "Fold 5\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.210122\tvalid_1's binary_logloss: 0.222419\n",
      "[2000]\ttraining's binary_logloss: 0.186476\tvalid_1's binary_logloss: 0.205044\n",
      "[3000]\ttraining's binary_logloss: 0.173375\tvalid_1's binary_logloss: 0.199882\n",
      "[4000]\ttraining's binary_logloss: 0.162741\tvalid_1's binary_logloss: 0.197436\n",
      "[5000]\ttraining's binary_logloss: 0.153451\tvalid_1's binary_logloss: 0.196247\n",
      "[6000]\ttraining's binary_logloss: 0.145035\tvalid_1's binary_logloss: 0.195294\n",
      "[7000]\ttraining's binary_logloss: 0.137398\tvalid_1's binary_logloss: 0.195078\n",
      "[8000]\ttraining's binary_logloss: 0.13028\tvalid_1's binary_logloss: 0.194779\n",
      "[9000]\ttraining's binary_logloss: 0.12364\tvalid_1's binary_logloss: 0.194698\n",
      "[10000]\ttraining's binary_logloss: 0.117442\tvalid_1's binary_logloss: 0.1947\n",
      "[11000]\ttraining's binary_logloss: 0.111609\tvalid_1's binary_logloss: 0.1949\n",
      "Early stopping, best iteration is:\n",
      "[9525]\ttraining's binary_logloss: 0.120331\tvalid_1's binary_logloss: 0.194568\n",
      "Fold 6\n",
      "Training until validation scores don't improve for 2000 rounds\n",
      "[1000]\ttraining's binary_logloss: 0.210413\tvalid_1's binary_logloss: 0.219968\n",
      "[2000]\ttraining's binary_logloss: 0.186822\tvalid_1's binary_logloss: 0.202495\n",
      "[3000]\ttraining's binary_logloss: 0.173706\tvalid_1's binary_logloss: 0.197481\n",
      "[4000]\ttraining's binary_logloss: 0.163109\tvalid_1's binary_logloss: 0.194923\n",
      "[5000]\ttraining's binary_logloss: 0.153821\tvalid_1's binary_logloss: 0.19369\n",
      "[6000]\ttraining's binary_logloss: 0.145459\tvalid_1's binary_logloss: 0.192927\n",
      "[7000]\ttraining's binary_logloss: 0.137808\tvalid_1's binary_logloss: 0.192408\n",
      "[8000]\ttraining's binary_logloss: 0.130725\tvalid_1's binary_logloss: 0.192349\n",
      "[9000]\ttraining's binary_logloss: 0.124136\tvalid_1's binary_logloss: 0.192304\n",
      "[10000]\ttraining's binary_logloss: 0.117958\tvalid_1's binary_logloss: 0.192319\n",
      "Early stopping, best iteration is:\n",
      "[8430]\ttraining's binary_logloss: 0.127841\tvalid_1's binary_logloss: 0.19223\n",
      "CV score: 0.90572 \n"
     ]
    }
   ],
   "source": [
    "#training and predicting lgb model with best param which we got through bayes optimization\n",
    "folds = StratifiedKFold(n_splits=7, shuffle=False, random_state=99999)\n",
    "oof = np.zeros(len(train_df))\n",
    "predictions = np.zeros(len(test_df))\n",
    "for fold_, (trn_idx, val_idx) in enumerate(folds.split(train_df.values, target.values)):\n",
    "    print(\"Fold {}\".format(fold_))\n",
    "    \n",
    "    #converting train data to lightgbm.basic.Dataset so that it can load faster\n",
    "    trn_data = lgb.Dataset(train_df.iloc[trn_idx][predictors], label=target.iloc[trn_idx])\n",
    "\n",
    "    #converting validation data to lightgbm.basic.Dataset so that it can load faster\n",
    "    val_data = lgb.Dataset(train_df.iloc[val_idx][predictors], label=target.iloc[val_idx])\n",
    "\n",
    "    clf = lgb.train(param, trn_data, 12000, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 2000)\n",
    "    oof[val_idx] = clf.predict(train_df.iloc[val_idx][predictors], num_iteration=clf.best_iteration)\n",
    "    predictions += clf.predict(test_df[predictors], num_iteration=clf.best_iteration) / folds.n_splits\n",
    "    \n",
    "    #save mode at each fold\n",
    "    clf.save_model('models/clf_cv'+str(fold_+1)+'.txt')\n",
    "    \n",
    "print(\"CV score: {:<8.5f}\".format(roc_auc_score(target, oof)))\n",
    "sub = pd.DataFrame({\"ID_code\": test_df.ID_code.values})\n",
    "sub[\"target\"] = predictions\n",
    "sub.to_csv(\"responce_code_aai.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 7. Finding Threshold </h2>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "The LGB model will give probablity as output .we need to find the thresholds value so that wer can classify points based the optimal value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(proba, threshould, fpr, tpr):\n",
    "    \n",
    "    t = threshould[np.argmax(tpr*(1-fpr))]\n",
    "    \n",
    "    # (tpr*(1-fpr)) will be maximum if your fpr is very low and tpr is very high\n",
    "    \n",
    "    print(\"the maximum value of tpr*(1-fpr)\", max(tpr*(1-fpr)), \"for threshold\", np.round(t,3))\n",
    "    predictions = []\n",
    "    for i in proba:\n",
    "        if i>=t:\n",
    "            predictions.append(1)\n",
    "        else:\n",
    "            predictions.append(0)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "train_fpr1, train_tpr1, tr_thresholds1 = roc_curve(target, oof)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the maximum value of tpr*(1-fpr) 0.6818016091088409 for threshold 0.095\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1, 'Confusion matrix for Train data')"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXMAAAEICAYAAACtXxSQAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjAsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+17YcXAAAgAElEQVR4nO3dd5wV1d3H8c93aYKKgCBiQZBgNBoDCoqJGlsUfcTyGI0ldsOjYhJLHkviE4gtib3F3jAWNFbsEsSgRqQIYg8oFgRREBtN2P09f8wsXJbdu3cvW2e/b17z4s6ZM2fO3Hv3t2fPnDmjiMDMzJq2koaugJmZrT4HczOzDHAwNzPLAAdzM7MMcDA3M8sAB3MzswxwMK9DktpKekzSV5L+sRrlHCHp2dqsW0ORtJOkd4vc9/uSJkv6RtJvartuq0vSLZJ+X0tlXSDpjtooy5oHB3NA0uGSJkr6VtJsSU9J2rEWiv450BVYNyIOLraQiLg7IvashfrUKUkh6Xv58kTECxHx/SIPcSbwfESsHRFXF1kGAJJuSD/vbyV9J2lpzvpTxZQZESdExEWrU69iSLpL0rD6Pq41Ls0+mEs6HbgSuIgk8HYHrgP2r4XiNwH+ExHLaqGsJk9Sy9UsYhPgzdo4dkScGBFrRcRaJJ/9feXrEbF3dfubNToR0WwXYB3gW+DgPHnakAT7WelyJdAm3bYLMBM4A/gMmA0cm277E/AdsDQ9xvHAMOCunLJ7AAG0TNePAd4HvgFmAEfkpL+Ys9+PgQnAV+n/P87Z9jxwPvBSWs6zQOcqzq28/mfm1P8AYB/gP8AXwO9z8m8HvAx8mea9FmidbhubnsuC9Hx/kVP+WcCnwN/L09J9eqXH2CZd3wCYC+xSSV2fA0qBxWn5m6Wf353A58CHwLlASc579hJwRXqMC/J8xit9Lmna99LzORb4KD1+CfBAei5fpu/1Fjn73AUMS1/vAXyQvrefk3x3jspTh02BF9LP7BngeuCOdFuVxwVOJvmOfZe+Lw+n6eey4rv0JrBfQ/+8eanbpcEr0KAnDwOBZaTBtIo85wHjgPWALsC/gfPTbbuk+58HtEqD4EKgY7p9pSBRyXqPNGC0BNYEvga+n27rBmyZvj6GNJgDnYD5wJHpfoel6+um258H3kuDXdt0/S9VnFt5/f+Y1v9XaeC5B1gb2JIkeG6a5t8WGJAetwfwNnBqTnkBfK+S8v9K8kuxLTnBPM3zq7ScdmkQuzTPZ/E8cELO+p3Ao2lde5D8Ajo+5z1bBvw6rW/bPOWu9LmkaeXB/Pa0bm1Jguox6fHWIPllNjFnn4rBfBkwNH1v9yP5Rde+ijqMBy5J36ddSQLzHem2go+bk3YIyXeoBDg8La9rQ//Meam7pbl3s6wLzI383SBHAOdFxGcR8TlJi/vInO1L0+1LI+JJkh+aYvuEy4CtJLWNiNkRUVmXwn8B0yLi7xGxLCLuBd4BBuXkuT0i/hMRi4D7gT55jrkUuDAilgIjgM7AVRHxTXr8N4GtASJiUkSMS4/7AXAj8NMCzmloRCxJ67OSiLgZmAa8QhJ8/lBNeQBIakHS+j8nresHwGWs/NnMiohr0vqucuwCDY2IhRGxKCLKIuKO9HiLSX4JbCtpzSr2XUzyF8HSiBgJLCH5JVvxXDYl+YzK36cxwJPl24s4LhFxf/odKouIe0j+SuhXzBtgTUNzD+bzgM7V9IduQPInfLkP07TlZVT4ZbAQWKumFYmIBSTB6URgtqQnJG1eQH3K67RhzvqnNajPvIgoTV+XB7w5OdsXle8vaTNJj0v6VNLXJH3NnfOUDfB5GoDyuRnYCrgmIpZUk7dcZ6A1q342ue/DxwWWlc/yMiS1kHSxpPfT85+eU5fKzM15b6Hqz2IDks9hYU7a8vMq4rhIOkbSa5K+lPQlsHm+/Nb0Nfdg/jJJ6+mAPHlmkVx4K9c9TSvGApI/2cutn7sxIp6JiJ+RtFDfIQly1dWnvE6fFFmnmriepF69I6I98HtA1eyTd1pOSWuRXIe4FRgmqVOBdZlL8ldFxc8m931Y7SlBIyK3jKNIutJ2I+mvLx+5U917UJ3ZwLqS2uakda/BcVc6z7Slfz1wEkn3WweSz21162mNWLMO5hHxFUl/8d8kHSCpnaRWkvaWdHGa7V7gXEldJHVO899V5CGnADtL6i5pHeCc8g2SukraL/3TeQlJd01pJWU8CWyWDqdsKekXwA+Ax4usU02sTdKv/236V8NJFbbPIbmQVxNXAZMi4gTgCeCGQnZKW7z3AxdKWlvSJsDpFP/ZFGJtks9mHskv5Qtro9CIeA+YSvLLrLWknUm60wo9bsX3fS2SAP85IEknkLTMLcOadTAHiIjLSYLAuSRf/o+BU4BH0iwXABNJftheB15N04o51ijgvrSsSawcgEtIRsXMIhl98VOSkQoVy5gH7JvmnUcyWmLfiJhbTJ1q6HckF9O+Ifmr4b4K24cBw9M/7Q+prjBJ+5NchD4xTTod2EbSEQXW59ckf+28D7xIcuH2tgL3LcbtrBjV9CbJxfDacijwE5LP/g8kI38KPe4twI8kzZf0QERMBa4muag6mySQv1KLdbVGSCv/FWlmZk1Rs2+Zm5llgYO5mVkGOJibmWWAg7mZWQbU+eRBS+e+7yustor9+g5p6CpYI/TUx0+t9lj4msScVp03zczYe7fMzcwywNN6mlm2lFV2r132OZibWbaUNs/HBziYm1mmRJQ1dBUahIO5mWVLmYO5mVnT55a5mVkG+AKomVkGuGVuZtb0hUezmJllgC+AmpllgLtZzMwywBdAzcwywC1zM7MM8AVQM7MM8AVQM7OmL8J95mZmTZ/7zM3MMsDdLGZmGeCWuZlZBpQubegaNAgHczPLFnezmJllgLtZzMwywC1zM7MMcDA3M2v6whdAzcwywH3mZmYZ4G4WM7MMcMvczCwD3DI3M8sAt8zNzDJgmR9OYWbW9DXTlnlJQ1fAzKxWlZUVvlRD0m2SPpP0Rk7aJZLekTRV0sOSOqTpPSQtkjQlXW7I2WdbSa9Lmi7paklK0ztJGiVpWvp/xzRdab7p6XG2qa6uDuZmli1RVvhSvTuAgRXSRgFbRcTWwH+Ac3K2vRcRfdLlxJz064HBQO90KS/zbGB0RPQGRqfrAHvn5B2c7p+Xg7mZZUsttswjYizwRYW0ZyOivGN+HLBRvjIkdQPaR8TLERHAncAB6eb9geHp6+EV0u+MxDigQ1pOlRzMzSxbatAylzRY0sScZXANj3Yc8FTOek9JkyX9S9JOadqGwMycPDPTNICuETEbIP1/vZx9Pq5in0r5AqiZZUsNRrNExE3ATcUcRtIfgGXA3WnSbKB7RMyTtC3wiKQtAVV26OqKr+k+DuZmli1RXZxcfZKOBvYFdk+7ToiIJcCS9PUkSe8Bm5G0qnO7YjYCZqWv50jqFhGz026Uz9L0mcDGVexTKXezmFm21GKfeWUkDQTOAvaLiIU56V0ktUhfb0py8fL9tPvkG0kD0lEsRwGPpruNBI5OXx9dIf2odFTLAOCr8u6YqrhlbmbZUou380u6F9gF6CxpJjCUZPRKG2BUOsJwXDpyZWfgPEnLgFLgxIgov3h6EsnImLYkfezl/ex/Ae6XdDzwEXBwmv4ksA8wHVgIHFtdXR3MzSxbavGmoYg4rJLkW6vI+yDwYBXbJgJbVZI+D9i9kvQAhtSkrg7mZpYtpaUNXYMG4WBuZtniWRPNzDLAwdzMLAOa6URbDuZmlilRVvfjzBsjB3MzyxZ3s5iZZYBHs5iZZYBb5mZmGeBgblU596LLGfvSeDp17MAjd92w0rbb73mAy/52Ky88MYKOHdbhm28XcPZ5FzN7zueULivlmMMP4sD/2hOAy/52K2P/PZ6yCHbo35dzTj0RSbz5zjTOvfByFi9Zwk479F+e/s609zn/kmtYuGgxG3Rbj78OPZO11lyzId4Cq0arNq245IFLaNW6FS1atODFJ1/krsvvYtDRgzjghAPYoMcG/GLrX/D1/K+X73Pin06k/279WbJoCZedfhnvvfEeAMedcxz9d+8PwL1X3cvYx8YCcOolp9J7695I4pP3P+Gy0y9j8cLF9X+yjV09TLTVGHmirQIcsM/PuOHyC1ZJnz3nc16eMJluXddbnnbvg4/Rq0d3Hhp+Hbdf+1cuueZmli5dyuTX32Ly62/x0J3X8cjfr+fNt//DhMmvA3D+pdcy9Kzf8OR9t/LRzFm8OG4iAEP/ciWnnnQsD//9enbf+cfcfneldwpbI7B0yVLO/sXZDNlrCEMGDmHbXbZl876b89bEtzjnsHOY8/GclfL337U/G/TcgON3Op6rz7qaUy46JUnfrT+9turFkL2GcOqgUznoxINot1Y7AG76000M2WsIJ+95Mp/N+oxBxwyq9/NsEup4oq3GysG8AP36/JB12q+9SvrFV9/I6Scfj3JmHpbEgoWLiAgWLlrMOu3XpkWLFkjiu+++Y+myZXy3dClLl5WybqcOfD73CxYsWEifrbZAEvsN3J3nXngZgA8+mkm/Pj8EYIf+2zDqXy/Wy/laccpbyS1btqRly5ZEBO+9+R6fzfxslbwD9hzA6AdHA/DO5HdYq/1adFyvI917d+f1V16nrLSMJYuWMOOtGWy7y7YALPx2+QR9tFmjTfUzYjdXZVH4kiF5g7mk1pKOlXRp+hDTYyW1qa/KNWZjXhjHel06s3nvTVdKP/ygQbz/wcfsuv8RHHjUSZx96omUlJTQZ6st6L/N1uy63xHsut8R/GT7bejVoztzPp9L1/U6L9+/a5fOzPl8HgDf27QHY14cB8CzY17g0zlz6+8ErcZKSkq49ulruXfKvUx+YTLvTnm3yrzrrr8uc2et+Dznzp5L5/U7M+PtGfTbpR9t1mhD+47t2XqHremyQZfl+U677DTuefUeNuq1ESNvH1mn59NklZYWvmRIlcFc0g+At0imf/yIZLL0XYA3021Vyn0U0y133lt7tW0kFi1ezE13juCUE45cZdtL4yexee9NGfPo3Tx4x9+46PLr+HbBAj6aOYv3P/iY0Q//neceuYvxk15j4pTXiUqaV+Ut/fN/fxr3PvgYhxz3axYsXESrVr7E0ZiVlZVxysBTOHK7I9msz2Zs8v1NqswrrfogmYjg1bGvMnHMRC575DLOuvYs3nn1HUqXrQg6V5xxBb/s90s+nv4xO++3c52cR1MXZWUFL1mSLzpcA5wUEaNyEyXtAfwN2LWqHXMfxbR07vvZ+lsG+PiT2Xwy61MOOvpkAOZ8PpeDj/s1I26+koefGMUJvzwESXTfaAM27LY+Mz6cyYTJr/OjLTenXbu2AOw4oB9T33yHQXvtzpzPVrTQ5nw+l/U6rwvApptszM1XXgQkXS5j/z2+ns/UirHg6wVMfXkq/Xbpx4fvflhpnrmz59J5gxV/kXXu1pl5c5K/yEZcM4IR14wA4MxrzmTWjJUfMFNWVsbYx8Zy0P8cxKj7V/rxNMhc90mh8nWzbFgxkANExD+B9euuSo3fZr16MvaJETz74HCefXA4Xbt05h+3XUPndTvRrWsXxk2aAsDcL+bzwUcz2WiD9enWtQsTp7zOsmWlLF22jIlTXmfTTTamS+dOtGvXltfeeJuIYOTTo9l1xwEAzJv/JZD88N44fASHHLBPg52z5bdOp3VYs30y0qj1Gq3pu1NfPp7+cZX5x40ax+4HJdNYb953cxZ8s4D5n82npKSEtTsk12d6bN6Dnlv0ZNLYSQB067Hi4ezb77E9M9+buWrBVqMHOmdJvpZ5iaQ26XPtlpO0RjX7Zc7/Dv0LEyZP5csvv2b3A37JyccfyUGD9qo074nHHM4fLryMA488iYjgtJOPo2OHddhz1x0Z/+prHHjUSUiw4/b92CUN2v/3u1NWDE0c0J+ddkiGpT056nlGPPQ4AHv89MfLhzha49NxvY787orfUdKiBJWIFx57gfGjx7Pfsftx8EkH07FLR64bdR0TnpvAVWdexYTnJtB/t/7c9uJtLF60mCvOuAKAFq1acOmDlwLJBc9LfnMJZaVlSOKMy8+g3drtkMSMt2Zw7e+vbchTbryaactcUcWYTEnnAgOAUyLigzStB3A1MDEizivkAFnsZrHVt1/fGj1ExZqJpz5+qrKn0tfIgj8eWnDMWfO8Eat9vMaiyhZ2RFwg6RRgrKR2gIBvgUsj4pr6qqCZWY1krPukUHm7SyLiWuBaSWun69/US63MzIrVTLtZqgzmko6qJG3564i4s47qZGZWtKwNOSxUvpZ5/0rSBAwCNgQczM2s8XHLfGUR8evy10qa5EcAZwHjgAvrvmpmZkVwMF+VpJbAMcAZwCvAzyOi6nuUzcwaWsZu0y9Uvj7zIcBvgdHAwIio/FY2M7NGxM8AXdU1wGfAjsBjORc/BUREbF3HdTMzqzkH81X0rLdamJnVFo9mWZm7VcysSWqmLfOCHk4h6aZ862ZmjUYtPpxC0m2SPpP0Rk5aJ0mjJE1L/++YpkvS1ZKmS5oqaZucfY5O80+TdHRO+raSXk/3uTodOVjlMfIp9ElDN1azbmbWKERpWcFLAe4ABlZIOxsYHRG9SQaInJ2m7w30TpfBwPWQBGZgKLA9sB0wNCc4X5/mLd9vYDXHqFJBwTwiJuVbNzNrNGqxZR4RY4EvKiTvDwxPXw8HDshJvzMS44AOkroBewGjIuKLiJgPjAIGptvaR8TLkcx4eGeFsio7RpXyDU18jDxPGYyI/aor3MysvtVkaKKkwSQt43I3pQ/XyadrRMwGiIjZksqf6L4hkDuJ/cw0LV/6zErS8x2jSvlGs1xa3c5mZo1ODYJ57lPRakFl0+lGEelFyTea5V/FFmpm1mDqfmTiHEnd0hZzN5L7cSBpWW+ck28jYBYrnp+cm/58mr5RJfnzHaNK1faZS+ot6QFJb0l6v3ypbj8zs4YQy8oKXoo0EigfkXI08GhO+lHpqJYBwFdpV8kzwJ6SOqYXPvcEnkm3fSNpQDqK5agKZVV2jCoV8vi320muxF5B8hDnY6n8zwMzs4ZXiy1zSfeStKo7S5pJEgv/Atwv6XjgI+DgNPuTwD7AdGAhSawkIr6QdD4wIc13XkSUX1Q9iWTETFvgqXQhzzGqVEgwbxsRoyUpvZFomKQX0pMyM2tUanNulog4rIpNu1eSN4BKn4cYEbcBt1WSPhHYqpL0eZUdI59CgvliSSXAtPQxcp8A1V5ZNTNrEM3zbv6CxpmfCrQDfgNsCxzJir4cM7NGJcqi4CVLqm2ZR0R5P8+3pH1AZmaNVjNtmVcbzCWNoZKxjxGxW53UyMxsNcSyhq5Bwyikz/x3Oa/XAA4CmunbZWaNXbhlXrlK5mF5SZJvKDKzxsnBvHLpjF/lSkgugq5fZzUyM1sNbplXbRIr5hFYBswAjq/LSpmZFcvBvGpbRMTi3ARJbeqoPmZmqyVKm+cN6oWMM/93JWkv13ZFzMxqQ5QVvmRJvvnM1yeZW7etpL6smI+lPclNRGZmjU6UNc+Web5ulr2AY0imZbyMFcH8a+D3dVstM7PiZK3FXah885kPB4ZLOigiHqzHOpmZFS2iebbMC+kz31ZSh/KVdE7eC+qwTmZmRWuufeaFBPO9I+LL8pX0gaT71F2VzMyKV1aqgpcsKWRoYgtJbSJiCYCktoCHJppZo+QLoFW7Cxgt6fZ0/VhgeN1VycyseA7mVYiIiyVNBfYgGdHyNLBJXVfMzKwYka1pygtWSMsc4FOS6WsOIbmd36NbzKxRcsu8AkmbAYcChwHzgPsARcSu9VQ3M7Maa65DE/O1zN8BXgAGRcR0AEmn1UutzMyKVJqxUSqFyjc08SCS7pUxkm6WtDsr7gI1M2uUIlTwkiVVBvOIeDgifgFsDjwPnAZ0lXS9pD3rqX5mZjUSZSp4yZJqbxqKiAURcXdE7EsyT8sU4Ow6r5mZWREiCl+ypNDRLABExBfAjeliZtboZK3FXagaBXMzs8autKyQWUqyx8HczDIla90nhXIwN7NMKcvYKJVCOZibWaZkbchhoZpn55KZZVZtjWaR9H1JU3KWryWdKmmYpE9y0vfJ2eccSdMlvStpr5z0gWnadEln56T3lPSKpGmS7pPUutjzVtRxB1PL1hs20x4sy6d7+/UaugrWCL0/d/JqN6snbnRAwTGn38xHCjqepBbAJ8D2JDPHfhsRl1bI8wPgXmA7YAPgn8Bm6eb/AD8DZgITgMMi4i1J9wMPRcQISTcAr0XE9YXWP5db5maWKaVlJQUvNbA78F5EfJgnz/7AiIhYEhEzgOkkgX07YHpEvB8R3wEjgP0lCdgNeCDdfzhwQA1PdzkHczPLlKjBImmwpIk5y+Aqij2UpNVd7hRJUyXdJqljmrYh8HFOnplpWlXp6wJfRsSyCulFcTA3s0wpCxW8RMRNEdEvZ7mpYnlpP/Z+wD/SpOuBXkAfYDZwWXnWSqoTRaQXxaNZzCxT6mA0y97AqxExJyk/+R9A0s3A4+nqTGDjnP02AmalrytLnwt0kNQybZ3n5q8xt8zNLFPKarAU6DByulgkdcvZdiDwRvp6JHCopDaSegK9gfEkFzx7pyNXWpN02YyMZPTJGODn6f5HA4/W4FRX4pa5mWVK1OJM3ZLakYxC+Z+c5Isl9SHpEvmgfFtEvJmOTnkLWAYMiYjStJxTgGeAFsBtEfFmWtZZwAhJFwCTgVuLrquHJlpD8NBEq0xtDE18rushBcec3ebcn5k7jNwyN7NMqc2WeVPiYG5mmVKDvvBMcTA3s0xxy9zMLAPcMjczy4BSt8zNzJq+ZvrUOAdzM8uWMrfMzcyavuZ6Y4uDuZllii+AmpllQJnczWJm1uSVNnQFGoiDuZllikezmJllgEezmJllgEezmJllgLtZzMwywEMTzcwyoNQtczOzps8tczOzDHAwNzPLgHA3i5lZ0+eWuZlZBvh2fjOzDPA4czOzDHA3i5lZBjiYm5llgOdmMTPLAPeZm5llQHMdzVLS0BUwM6tNZUTBS3UkfSDpdUlTJE1M0zpJGiVpWvp/xzRdkq6WNF3SVEnb5JRzdJp/mqSjc9K3Tcufnu5b9N8VDuZmlillNVgKtGtE9ImIfun62cDoiOgNjE7XAfYGeqfLYOB6SII/MBTYHtgOGFr+CyDNMzhnv4E1Pd9yDuZmlilRg6VI+wPD09fDgQNy0u+MxDigg6RuwF7AqIj4IiLmA6OAgem29hHxckQEcGdOWTXmYG5mmVKTlrmkwZIm5iyDKxQXwLOSJuVs6xoRswHS/9dL0zcEPs7Zd2aali99ZiXpRfEFUDPLlGUqvM0dETcBN+XJ8pOImCVpPWCUpHfy5K2svzuKSC+KW+Zmlim12c0SEbPS/z8DHibp856TdpGQ/v9Zmn0msHHO7hsBs6pJ36iS9KI4mJtZptTWBVBJa0pau/w1sCfwBjASKB+RcjTwaPp6JHBUOqplAPBV2g3zDLCnpI7phc89gWfSbd9IGpCOYjkqp6waczeLmWVKIUMOC9QVeDgdLdgSuCcinpY0Abhf0vHAR8DBaf4ngX2A6cBC4FiAiPhC0vnAhDTfeRHxRfr6JOAOoC3wVLoUxcHczDKltkJ5RLwP/KiS9HnA7pWkBzCkirJuA26rJH0isNVqVxYHczPLGE+0ZWaWAaXNdKotB3MzyxS3zM3MMiDcMjcza/qaa8vc48xXQ5s2bXj5pceZNHEUr015jqF/PAOAW2+5gmnvvszECc8yccKz/OhHWwIwaNCevDppFBMnPMu4l5/kJz/uD8CPfrQlL44dyWtTnuPVSaM4+OD9GuycrDh/vWoo498ezVMv/GOl9KNOOJR/jnuYp198gLOG/haADTfuxlsfv8zjY0bw+JgRXHDpH5bnb9WqJRdefi6jX3mEUS8/xMB9Vwya2Gf/n/HMSw/y9IsPcOWNF9XPiTVBtTlrYlPilvlqWLJkCXvseQgLFiykZcuWjH3+YZ5+egwAZ51zAQ899MRK+Z977kUee+xZAH74wy24954b2OqHP2XhwkUcc9xvmT59Bt26dWX8uKd49tnn+eqrr+v9nKw4D4x4jDtvvY9L/3b+8rQBO/bjZ3vvwj47H8J33y1l3c4dl2/78IOZ7LvroauUM+T0E5j3+Rfsvv0BSKJDx3UA6LFpd0767XEcvM8xfP3VNyuVZSvLVogunIP5alqwYCGQtKhatmpFMtQ0f16ANdu1W5532rT3l6fPnj2Hzz6fR5cu6zqYNyETXn6VDTfutlLaEccczA1X3c533y0FYN7c+dWW8/PD9+dnOxwIQEQw/4svAfjFkQfy99vu5+uvvim4rOZqWTMN5+5mWU0lJSVMnPAssz+ZyujRYxk/YTIA5593Fq9OGsVllwyjdevWy/Pvv/9A3nj9X4x8dDi/+tUZq5TXv18fWrduxXvvfVBfp2B1pGevTei/Q18eeuZO7h15C1v3/cHybRt335DHnruXe0feQv8BfQFYu/1aAJx+zhBGPncP1956MZ27dFpeVs9e3bn/idt58Onh7Lzbj+v/hJqIqMG/LKkymEsaJGmTnPU/SnpN0khJPfMVmjutZFnZgtqsb6NTVlZGv/57sknPfvTv15ctt/w+fzj3z2y51c4M2OG/6NipA2f+78nL8z/66NNs9cOfctDPj+dPw/53pbLWX3897rjjak444fS8LXxrGlq0bEH7ddrz33sdxZ+HXsE1t1wMwOdz5rJjn70ZtNthXPh/l3HFjRex1lpr0rJlSzbYcH0mvTKF/XY7nMkTp3LOn04DoGXLFvTYtDuH7/8rfjv4HP585R+XB39bWR08nKJJyNcyvxD4HEDSvsAvgeNIJpO5IV+hEXFTRPSLiH4lJWvWVl0bta+++pp/jf03e+25C59+mkyi9t133zF8+H3079d3lfwvvPgKm266Ceuum/R9rr32Wox89E7+OPRiXhn/ar3W3erGp7Pm8MwTowGYOvlNysrK6LRuR777bilfzv8KgDdee5uPPphJz+9twvwvvmThgkU888RzADz56Ci23HqLtKzP+OdTz7Ns2TJmfjSLGdM/oGev7g1zYo2cW+ariogo7+T9b+DWiG6f1ioAAAsJSURBVJgUEbcAXeq+ao1f586dWGed9gCsscYa7L7bTrz77nusv/56y/Pst99A3nwrmQK5V68ey9P79tmK1q1bMW/efFq1asWD/7iVu+56gAcffLxez8HqzqinnmeHnbYDoGev7rRq3Yov5s2n07odKSlJfvQ23mRDemzanY8+SJ5RMPrZsQzYMXk62Y933o7p7ybXU559cgwDdkxGP3Xs1IEevTbhow8+qe9TahKaa8s83wVQSVqLZPav3YHrcratUae1aiK6devKbbdeSYsWJZSUlPDAA4/xxJP/ZNQz99O5Syck8dprb3LykOQRgf994D788pc/Z+nSZSxetJjDjzgJgIMPHsROO21Pp3U7ctRRhwBw/Amn8dprbzbYuVnNXHXTn9n+J9vSsVMHXpr6NFf99Qb+cfcj/PXqYTz1wj9YunQp/3vKHwHYbodtOPXskyhdVkppWSnn/u5Cvvoyudj91z9dxeXXX8D/XfA7vpg3nzN/PQyAsc/9m5123YFnXnqQstJS/jLsyuWte1tZaTPtolRVfbOSjgN+D3wNfBYRA9P0vsClEbHKrGGVadl6w+b5zlpe3duvV30ma3benzu56KfTlzt8kwMLjjn3fPjwah+vsaiyZR4Rt0l6huT5dq/lbPqUdJ5eM7PGJmt94YXKN5rllxHxSURMBnYoT0+fjuFbFM2sUWqufeb5LoCenvP6mgrbjquDupiZrTbfzr8qVfG6snUzs0ahuXaz5AvmUcXrytbNzBqF5jqaJV8w31zSVJJWeK/0Nen6pnVeMzOzImSt+6RQ+YL5FvVWCzOzWpK1C5uFyhfMzwLOjghP3WdmTUZz7TPPN5rlA2CSpMPrqS5mZqvNo1kqiIiLJd0NXC7peOB6cv6CiYiH6qF+ZmY10lxnHM37cIqI+ETSEyQzKA5iRTAPwMHczBqd0oy1uAtVZTCXtCVJa3wWsF1656eZWaOWte6TQuVrmT8A/DYinq2vypiZrS53s6yqT0QsqbeamJnVgubaMq9yNEtuIJd0U+62iutmZo2FnzSU343VrJuZNQqlEQUv+UjaWNIYSW9LelPSb9P0YZI+kTQlXfbJ2eccSdMlvStpr5z0gWnadEln56T3lPSKpGmS7pPUmiIVFMwjYlK+dTOzxqIWx5kvA86IiC2AAcAQST9It10REX3S5UmAdNuhwJbAQOA6SS0ktQD+BuwN/AA4LKecv6Zl9QbmA8cXe975RrM8Rp4JtSLCc5qbWaNTW33m6Qi+2enrbyS9DWyYZ5f9gRFpF/UMSdOB7dJt0yPifQBJI4D90/J2A8pvzBwODCMZRVhj+S6AXlpMgWZmDakmo1kkDQYG5yTdFBGrXBOU1APoC7wC/AQ4RdJRwESS1vt8kkA/Lme3mawI/h9XSN8eWBf4MiKWVZK/xvLdAfqvYgs1M2soNWmZp4E774CO9MH2DwKnRsTXkq4HzifpuTgfuIzkgT2VPechqLw7O/LkL0reO0ABJPUG/kzS17PG8iNGeBpcM2t0anOUiqRWJIH87vIpTCJiTs72m4HH09WZwMY5u29EctMlVaTPBTpIapm2znPz11ghF0BvJ+nDWQbsCtwJ/L3YA5qZ1aXSKCt4yUeSgFuBtyPi8pz0bjnZDgTeSF+PBA6V1EZST6A3MB6YAPROR660JrlIOjKS/qAxwM/T/Y8GHi32vKttmQNtI2K0JEXEh8AwSS8AQ4s9qJlZXanFO0B/AhwJvC5pSpr2e5LRKH1IukQ+AP4nPe6bku4H3iJp/A6JiFIASacAzwAtgNsi4s20vLOAEZIuACaT/PIoSiHBfLGkEmBaWqFPgPWKPaCZWV2qxdEsL1J5v/aTefa5kGRiworpT1a2XzrCZbuK6cUopJvlVKAd8BtgW5LfVEfXxsHNzGpbc70DtNqWeURMSF9+Cxxbt9UxM1s9ZZ5oq3KSxlDJcJmI2K1OamRmthqy1uIuVCF95r/Leb0GcBBJ576ZWaNT3SiVrCqkm6XiPCwvSfINRWbWKLmbpQqSOuWslpBcBF2/zmpkZrYa3M1StUmsuPV0GTCD1ZjZy8ysLrllXrUtImJxboKkNnVUHzOz1dJcW+aFjDP/dyVpL9d2RczMakNplBa8ZEm++czXJ5mOsa2kvqy4E6o9yU1EZmaNjh/ovKq9gGNIZvK6jBXB/GuS+QnMzBqd5vpA53zzmQ8Hhks6KCIerMc6mZkVrbm2zAvpM99WUofyFUkd0xm+zMwanbKIgpcsKSSY7x0RX5avpI9H2idPfjOzBuOJtqrWQlKb9CGlSGoLeGiimTVKvp2/ancBoyXdnq4fS/IUaTOzRqe59pkXMjfLxZKmAnuQjGh5GtikritmZlaMrPWFF6qQljnAp0AZcAjJ7fwe3WJmjZJb5hVI2ozkwaOHAfOA+wBFxK71VDczsxrzOPNVvQO8AAyKiOkAkk6rl1qZmRXJLfNVHUTSMh8j6WlgBJU/3NTMrNForqNZqhxnHhEPR8QvgM2B54HTgK6Srpe0Zz3Vz8ysRnzTUBUiYkFE3B0R+5LM0zIFOLvOa2ZmVoSIKHjJkkLuAF0uIr6IiBv9MGcza6x8B6iZWQZkrcVdKAdzM8uUrPWFF0rN9bdYQ5A0OCJuauh6WOPi74XVhhr1mdtqG9zQFbBGyd8LW20O5mZmGeBgbmaWAQ7m9cv9olYZfy9stfkCqJlZBrhlbmaWAQ7mZmYZ4GBeDUmlkqZIekPSPyS1W42ydpH0eCXpPSSFpF/npF0r6Zj0tSSdK2mapP9IGiNpy2LrYcWr6++DpDUkvSPphzlpZ0q6If2eLEqPX74cleY5TtLrkqamddu/+LO0psjBvHqLIqJPRGwFfAecmLsxDbS18T5+BvxWUutKtg0Bfgz8KCI2A/4MjJS0Ri0c12qmTr8PEbEYOBW4Li1rQ+B/gHPSLO+lxy9f7pS0EfAHYMeI2BoYAEwttg7WNDmY18wLwPfSFtLbkq4DXgU2lrSnpJclvZq22NYCkDQwbWm9CPx3nrI/B0YDR1ey7Szg1xGxECAingX+DRxRi+dmNVcn34eIeBqYDRwFXAEMi4j5eeqxHvAN8G26/7cRMaPWztKaBAfzAklqCewNvJ4mfR+4MyL6AguAc4E9ImIbYCJwetpyvhkYBOwErJ9TXj9Jt1Q4zF+AMyS1yMnXHlgzIt6rkHci4K6WBlIP34dTgQuBLhHx95z0XhW6WXYCXgPmADMk3S5pUF2cszVunmirem0lTUlfvwDcCmwAfBgR49L0AcAPgJckAbQGXiZ5sMeMiJgGIOku0lu3I2IicELugSJihqTxwOEF1EuQsTk8m4Z6+T5ExCxJzwEVr7G8FxF9KlZK0kCgP7A7cIWkbSNi2OqfrjUVDubVW1Txhyf9AV2QmwSMiojDKuTrQ80D7kXAA8BYgIj4WtICSZtGxPs5+bYB/lXDsm311ef3oSxdqhXJDSPjgfGSRgG3A8NqcCxr4tzNUjvGAT+R9D0ASe0kbUbyUOyeknql+Q6rqoByEfEO8Bawb07yJcDVktqm5e8B7AjcU3unYLWo1r4PhZC0gaRtcpL6AB/WRtnWdLhlXgsi4vN0GOG9ktqkyedGxH8kDQaekDQXeBHYCpI+UuDEiDihkiIvBCbnrF8DdARel1QKfArsHxGL6uaMbHXUwfchV6+cbh6A24BHgUslbQAsJrmYfmJlO1t2+XZ+M7MMcDeLmVkGOJibmWWAg7mZWQY4mJuZZYCDuZlZBjiYm5llgIO5mVkG/D+zWMcZUFDgxAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from seaborn import heatmap\n",
    "import matplotlib.pyplot as plt\n",
    "heatmap(confusion_matrix(target, predict(oof, tr_thresholds1, train_fpr1, train_tpr1)),annot=True, fmt=\"d\",xticklabels=[\"Pred:NO\",\"Pred:YES\"],yticklabels=[\"Actual:NO\",\"Actual:YES\"])\n",
    "plt.title(\"Confusion matrix for Train data\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2> 8. Saving Response code to json for later use</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving responce code to dict\n",
    "responce_dic = {}\n",
    "def t_encoding(tr,by):\n",
    "   \n",
    "    #calculating responce code\n",
    "    df = tr.groupby(by).agg({'target':['sum','count']})\n",
    "    cols = ['sum_y','count_y']\n",
    "    df.columns = cols\n",
    "    df = df.reset_index()\n",
    "    df = df.sort_values(by)\n",
    "    \n",
    "    df['r'] = df['sum_y'] / df['count_y']\n",
    "    mydict = dict(zip(df.iloc[:,0], df.r))\n",
    "    responce_dic[by] = mydict\n",
    "     \n",
    "    return \n",
    "\n",
    "for i in features:\n",
    "    te_r = t_encoding(train_df,i) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#saving dict to json for later use\n",
    "import json\n",
    "#save dictionary\n",
    "with open('responce_dic.json', 'w') as fp:\n",
    "    json.dump(responce_dic, fp)\n",
    "#load_dictionary \n",
    "with open('responce_dic.json', 'r') as fp:\n",
    "    responce_dic = json.load(fp)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
